{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [alan]:kouzhizhuo\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "You can find more info here:\n",
      "https://www.postgresql.org/docs/9.5/static/libpq-pgpass.html.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import wrds\n",
    "import psycopg2 \n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import *\n",
    "from pandas.tseries.offsets import *\n",
    "from scipy import stats\n",
    "conn=wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CRSP part\n",
    "crsp_m = conn.raw_sql(\"\"\"\n",
    "                      select a.permno, a.permco, a.date, b.shrcd, b.exchcd,\n",
    "                      a.ret, a.retx, a.shrout, a.prc, a.hsiccd\n",
    "                      from crsp.msf as a\n",
    "                      left join crsp.msenames as b\n",
    "                      on a.permno=b.permno\n",
    "                      and b.namedt<=a.date\n",
    "                      and a.date<=b.nameendt\n",
    "                      where a.date between '01/01/1990' and '12/31/2019'\n",
    "                      and b.exchcd between 1 and 3\n",
    "             \n",
    "                      \"\"\") \n",
    "\n",
    "\n",
    "# change variable format\n",
    "crsp_m[['permco','permno','shrcd','exchcd']]=crsp_m[['permco','permno','shrcd','exchcd']].astype(int)\n",
    "# SIC code \n",
    "crsp_m=crsp_m[(crsp_m['hsiccd']<6000)|(crsp_m['hsiccd']>6999)]\n",
    "\n",
    "\n",
    "# Line up date to end of month\n",
    "crsp_m['date']=pd.to_datetime(crsp_m['date'])\n",
    "crsp_m['jdate']=crsp_m['date']+MonthEnd(0)\n",
    "\n",
    "# add delisting return\n",
    "dlret = conn.raw_sql(\"\"\"\n",
    "                     select permno, dlret, dlstdt \n",
    "                     from crsp.msedelist\n",
    "                     \"\"\")\n",
    "dlret.permno=dlret.permno.astype(int)\n",
    "dlret['dlstdt']=pd.to_datetime(dlret['dlstdt'])\n",
    "dlret['jdate']=dlret['dlstdt']+MonthEnd(0)\n",
    "\n",
    "crsp = pd.merge(crsp_m, dlret, how='left',on=['permno','jdate'])\n",
    "crsp['dlret']=crsp['dlret'].fillna(0)\n",
    "crsp['ret']=crsp['ret'].fillna(0)\n",
    "crsp['retadj']=(1+crsp['ret'])*(1+crsp['dlret'])-1\n",
    "crsp['me']=crsp['prc'].abs()*crsp['shrout'] # calculate market equity\n",
    "crsp=crsp.drop(['dlret','dlstdt','prc','shrout'], axis=1)\n",
    "crsp=crsp.sort_values(by=['jdate','permco','me'])\n",
    "\n",
    "### Aggregate About Market Cap \n",
    "# sum of me across different permno belonging to same permco a given date\n",
    "crsp_summe = crsp.groupby(['jdate','permco'])['me'].sum().reset_index()\n",
    "# largest mktcap within a permco/date\n",
    "crsp_maxme = crsp.groupby(['jdate','permco'])['me'].max().reset_index()\n",
    "# join by jdate/maxme to find the permno\n",
    "crsp1=pd.merge(crsp, crsp_maxme, how='inner', on=['jdate','permco','me'])\n",
    "# drop me column and replace with the sum me\n",
    "crsp1=crsp1.drop(['me'], axis=1)\n",
    "# join with sum of me to get the correct market cap info\n",
    "crsp2=pd.merge(crsp1, crsp_summe, how='inner', on=['jdate','permco'])\n",
    "# sort by permno and date and also drop duplicates\n",
    "crsp2=crsp2.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "\n",
    "# keep December as market cap\n",
    "crsp2['year']=crsp2['jdate'].dt.year\n",
    "crsp2['month']=crsp2['jdate'].dt.month\n",
    "\n",
    "\n",
    "### July to June dates\n",
    "crsp2['ffdate']=crsp2['jdate']+MonthEnd(-6)\n",
    "crsp2['ffyear']=crsp2['ffdate'].dt.year\n",
    "crsp2['ffmonth']=crsp2['ffdate'].dt.month\n",
    "crsp2['1+retx']=1+crsp2['retx']\n",
    "crsp2=crsp2.sort_values(by=['permno','date'])\n",
    "\n",
    "# cumret by stock\n",
    "crsp2['cumretx']=crsp2.groupby(['permno','ffyear'])['1+retx'].cumprod()\n",
    "\n",
    "# lag cumret\n",
    "crsp2['lcumretx']=crsp2.groupby(['permno'])['cumretx'].shift(1)\n",
    "\n",
    "# found out lag market cap\n",
    "crsp2['lme']=crsp2.groupby(['permno'])['me'].shift(1)\n",
    "\n",
    "# if first permno then use me/(1+retx) to replace the missing value\n",
    "crsp2['count']=crsp2.groupby(['permno']).cumcount()\n",
    "crsp2['lme']=np.where(crsp2['count']==0, crsp2['me']/crsp2['1+retx'], crsp2['lme'])\n",
    "\n",
    "# baseline me\n",
    "mebase=crsp2[crsp2['ffmonth']==1][['permno','ffyear', 'lme']].rename(columns={'lme':'mebase'})\n",
    "\n",
    "# overall result\n",
    "crsp3=pd.merge(crsp2, mebase, how='left', on=['permno','ffyear'])\n",
    "crsp3['wt']=np.where(crsp3['ffmonth']==1, crsp3['lme'], crsp3['mebase']*crsp3['lcumretx'])\n",
    "\n",
    "# Information of June\n",
    "crsp_jun = crsp3[crsp3['month']==6]\n",
    "crsp_jun=crsp_jun[['permno','date', 'jdate', 'shrcd','exchcd','retadj','me','wt','cumretx','mebase','lme']]\n",
    "crsp_jun=crsp_jun.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Annual Block of compustat \n",
    "comp = conn.raw_sql(\"\"\"\n",
    "                    select gvkey, datadate, at, pstkl, txditc,\n",
    "                    pstkrv, seq, pstk\n",
    "                    from comp.funda\n",
    "                    where indfmt='INDL' \n",
    "                    and datafmt='STD'\n",
    "                    and popsrc='D'\n",
    "                    and consol='C'\n",
    "                    and datadate >= '01/01/1990'\n",
    "                    \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comp['datadate']=pd.to_datetime(comp['datadate']) #convert datadate to date fmt\n",
    "comp['year']=comp['datadate'].dt.year\n",
    "\n",
    "#years in Compustat\n",
    "comp=comp.sort_values(by=['gvkey','datadate'])\n",
    "comp['count']=comp.groupby(['gvkey']).cumcount()\n",
    "\n",
    "# lag the total assest\n",
    "comp=comp.sort_values(by=['gvkey','datadate'])\n",
    "comp['lat']=comp.groupby(['gvkey'])['at'].shift(1)\n",
    "\n",
    "#I/A function\n",
    "comp['I/A']=(comp['at']/comp['lat'])-1\n",
    "comp['year']=comp['year']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count Number of Years in Compustat\n",
    "comp=comp.sort_values(by=['gvkey','datadate'])\n",
    "comp['count']=comp.groupby(['gvkey']).cumcount()\n",
    "comp=comp[['gvkey','datadate','year','I/A','count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Quarter Block\n",
    "cp = conn.raw_sql(\"\"\"\n",
    "                    select gvkey, rdq, datadate, ibq, atq, seqq, txditcq, ceqq, pstkq, \n",
    "                    ltq, pstkrq, exchg\n",
    "                    from comp.fundq\n",
    "                    where indfmt='INDL' \n",
    "                    and datafmt='STD'\n",
    "                    and popsrc='D'\n",
    "                    and consol='C'\n",
    "                    and datadate >= '01/01/1990'\n",
    "                    \"\"\")\n",
    "\n",
    "cp['rdq']=pd.to_datetime(cp['rdq']) #convert datadate to date fmt\n",
    "cp['datadate']=pd.to_datetime(cp['datadate']) #convert datadate to date fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shareholders' equity\n",
    "cp['se']=np.where(cp['seqq'].isnull(), (cp['ceqq']+cp['pstkq']), cp['seqq'])\n",
    "cp['se']=np.where(cp['se'].isnull(),(cp['atq']-cp['ltq']), cp['se'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose Preferrerd Stock\n",
    "cp['ps']=np.where(cp['pstkrq'].isnull(), cp['pstkq'], cp['pstkrq'])\n",
    "cp['ps']=np.where(cp['ps'].isnull(),0,cp['ps'])\n",
    "\n",
    "cp['txditcq']=cp['txditcq'].fillna(0)\n",
    "\n",
    "# create book equity\n",
    "cp['be']=cp['se']+cp['txditcq']-cp['ps']\n",
    "cp['be']=np.where(cp['be']>0, cp['be'], np.nan)\n",
    "\n",
    "\n",
    "# lag book equity\n",
    "cp=cp.sort_values(by=['gvkey','rdq'])\n",
    "cp['lbe']=cp.groupby(['gvkey'])['be'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ROE\n",
    "cp['ROE']=cp['ibq']/cp['lbe']\n",
    "\n",
    "#report date of the month\n",
    "cp['rdqend']=cp['rdq']+MonthEnd(0)\n",
    "\n",
    "#lag report date\n",
    "cp=cp.sort_values(by=['gvkey','datadate'])\n",
    "cp['lrdq']=cp.groupby(['gvkey'])['rdq'].shift(1)\n",
    "cp['llrdq']=cp.groupby(['gvkey'])['lrdq'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "cp=cp.dropna(subset=['lrdq'])\n",
    "cp['datediff']=cp['datadate']-cp['lrdq']\n",
    "cp['datediff']=cp['datediff'].dt.days\n",
    "cp['datediff']=np.where(cp['datediff']<0, (cp['datadate']-cp['llrdq']).dt.days, cp['datediff'])\n",
    "cp=cp[(cp['datediff']<=183)&(cp['datediff']>=0)]\n",
    "\n",
    "cp=cp[['gvkey','datadate','ROE','rdq','rdqend','exchg','lrdq','be']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CCM Part\n",
    "import pyreadstat\n",
    "ccm, meta = pyreadstat.read_sas7bdat('ccmlinktable.sas7bdat')\n",
    "ccm.columns= ccm.columns.str.lower()\n",
    "ccm=ccm[['gvkey','lpermno', 'linktype', 'linkprim', 'linkdt', 'linkenddt']]\n",
    "ccm=ccm.rename(columns={'lpermno':'permno'})\n",
    "ccm=ccm[(ccm['linkprim'] =='C')|(ccm['linkprim'] =='P')]\n",
    "ccm=ccm[(ccm['linktype'] !='NR') & (ccm['linktype']  !='NU')]\n",
    "\n",
    "ccm['linkdt'] = pd.to_timedelta(ccm['linkdt'], unit='D') + pd.Timestamp('1960-01-01')\n",
    "ccm['linkenddt'] = pd.to_timedelta(ccm['linkenddt'], unit='D') + pd.Timestamp('1960-01-01')\n",
    "\n",
    "ccm['linkdt']=pd.to_datetime(ccm['linkdt'])\n",
    "ccm['linkenddt']=pd.to_datetime(ccm['linkenddt'])\n",
    "# if linkenddt is missing then set to today date\n",
    "ccm['linkenddt']=ccm['linkenddt'].fillna(pd.to_datetime('today'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge I/A\n",
    "ccm1=pd.merge(comp[['gvkey','datadate','I/A', 'count']],ccm,how='left',on=['gvkey'])\n",
    "ccm1['yearend']=ccm1['datadate']+YearEnd(0)\n",
    "ccm1['jdate']=ccm1['yearend']+MonthEnd(6)\n",
    "    # set link date bounds\n",
    "ccm2=ccm1[(ccm1['jdate']>=ccm1['linkdt'])&(ccm1['jdate']<=ccm1['linkenddt'])]\n",
    "ccm2=ccm2[['gvkey','permno','datadate','yearend', 'jdate','I/A', 'count']]\n",
    "\n",
    "# merge size\n",
    "ccm_jun=pd.merge(crsp_jun, ccm2, how='inner', on=['permno', 'jdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select NYSE as breakpoint\n",
    "nyse=ccm_jun[(ccm_jun['exchcd']==1) & (ccm_jun['me']>0) & (ccm_jun['count']>1) & ((ccm_jun['shrcd']==10) | (ccm_jun['shrcd']==11))]\n",
    "# size breakpoint\n",
    "nyse_sz=nyse.groupby(['jdate'])['me'].median().to_frame().reset_index().rename(columns={'me':'sizemedn'})\n",
    "# IA breakpoint\n",
    "nyse_ia=nyse.groupby(['jdate'])['I/A'].describe(percentiles=[0.3, 0.7]).reset_index()\n",
    "nyse_ia=nyse_ia[['jdate','30%','70%']].rename(columns={'30%':'IA30', '70%':'IA70'})\n",
    "nyse_breaks = pd.merge(nyse_sz, nyse_ia, how='inner', on=['jdate'])\n",
    "# join back size and IA breakdown\n",
    "ccm1_jun = pd.merge(ccm_jun, nyse_breaks, how='left', on=['jdate'])\n",
    "\n",
    "#assign size to B&M\n",
    "def sz_bucket(row):\n",
    "    if row['me']==np.nan:\n",
    "        value=''\n",
    "    elif row['me']<=row['sizemedn']:\n",
    "        value='S'\n",
    "    else:\n",
    "        value='B'\n",
    "    return value\n",
    "\n",
    "#assign I/A to H&M&L\n",
    "def ia_bucket(row):\n",
    "    if row['I/A']<=row['IA30']:\n",
    "        value = 'L'\n",
    "    elif row['I/A']<=row['IA70']:\n",
    "        value='M'\n",
    "    elif row['I/A']>row['IA70']:\n",
    "        value='H'\n",
    "    else:\n",
    "        value=''\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge ccm & crsp\n",
    "cr3=crsp3[['permno','date','jdate']]\n",
    "ccmcrsp=pd.merge(cr3,ccm,how='left',on=['permno'])\n",
    "# set link date bounds\n",
    "ccmcrsp2=ccmcrsp[(ccmcrsp['jdate']>=ccmcrsp['linkdt'])&(ccmcrsp['jdate']<=ccmcrsp['linkenddt'])]\n",
    "ccmcrsp2=ccmcrsp2[['gvkey','permno','date', 'jdate']]\n",
    "\n",
    "#merge compustata quaterly\n",
    "ccmcp=pd.merge(ccmcrsp2, cp, how='left', on=['gvkey'])\n",
    "ccmcp2=ccmcp[(ccmcp['jdate']>=ccmcp['lrdq'])&(ccmcp['jdate']<ccmcp['rdq'])]\n",
    "ccmcp2=ccmcp2.rename(columns={'lrdq':'matchrdq'})\n",
    "ccmcp3=ccmcp2[['permno','gvkey','matchrdq','date','jdate']]\n",
    "\n",
    "cp2=cp.copy()\n",
    "cp2['matchrdq']=cp2['rdq']\n",
    "ccmcp4=pd.merge(ccmcp3, cp2, how='left', on=['gvkey','matchrdq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###NYSE as breakpoint\n",
    "nyse2=ccmcp4[ccmcp4['exchg']==11]\n",
    "\n",
    "# ROE breakpoint\n",
    "nyse_roe=nyse2.groupby(['jdate'])['ROE'].describe(percentiles=[0.3, 0.7]).reset_index()\n",
    "nyse_roe=nyse_roe[['jdate','30%','70%']].rename(columns={'30%':'roe30', '70%':'roe70'})\n",
    "# join back ROE\n",
    "ccmcp5 = pd.merge(ccmcp4, nyse_roe, how='left', on=['jdate'])\n",
    "\n",
    "#assign ROE to X&Z&D\n",
    "def roe_bucket(row):\n",
    "    if row['ROE']<=row['roe30']:\n",
    "        value = 'X'\n",
    "    elif row['ROE']<=row['roe70']:\n",
    "        value='Z'\n",
    "    elif row['ROE']>row['roe70']:\n",
    "        value='D'\n",
    "    else:\n",
    "        value=''\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "###factors\n",
    "# assign size portfolio\n",
    "ccm1_jun['szport']=np.where((ccm1_jun['me']>0)&(ccm1_jun['count']>=1), ccm1_jun.apply(sz_bucket, axis=1), '')\n",
    "# assign book-to-market portfolio\n",
    "ccm1_jun['iaport']=np.where((ccm1_jun['me']>0)&(ccm1_jun['count']>=1), ccm1_jun.apply(ia_bucket, axis=1), '')\n",
    "# create positiveme and nonmissport variable\n",
    "ccm1_jun['posme']=np.where((ccm1_jun['me']>0)&(ccm1_jun['count']>=1), 1, 0)\n",
    "ccm1_jun['nonmissport']=np.where((ccm1_jun['iaport']!=''), 1, 0)\n",
    "\n",
    "# store portfolio assignment as of June\n",
    "june=ccm1_jun[['permno','date', 'jdate', 'iaport','szport','posme','nonmissport']]\n",
    "june['ffyear']=june['jdate'].dt.year\n",
    "\n",
    "#assign roe portfolio\n",
    "ccmcp5['roeport']=np.where(ccmcp5['ROE'].isnull(),'', ccmcp5.apply(roe_bucket, axis=1))\n",
    "ccmcp5['nonmiss']=np.where((ccmcp5['roeport']!=''), 1, 0)\n",
    "ccmcp5=ccmcp5[['permno','date','jdate','roeport','nonmiss']]\n",
    "ccmcp5['usedate']=ccmcp5['jdate']+MonthEnd(1)\n",
    "ccmcp5=ccmcp5.rename(columns={'jdate':'fmdate'})\n",
    "\n",
    "\n",
    "###merge monthly\n",
    "crsp3 = crsp3[['date','permno','shrcd','exchcd','retadj','me','wt','cumretx','ffyear','jdate']]\n",
    "ccm_3=pd.merge(crsp3, \n",
    "        june[['permno','ffyear','szport','iaport','posme','nonmissport']], how='left', on=['permno','ffyear'])\n",
    "ccm_4=pd.merge(ccm_3, ccmcp5, how='left', left_on=['permno','jdate'], right_on=['permno','usedate'])\n",
    "\n",
    "#keep criteria data\n",
    "ccm_5=ccm_4[(ccm_4['wt']>0)& (ccm_4['posme']==1) & (ccm_4['nonmissport']==1) & (ccm_4['nonmiss']==1)&\n",
    "          ((ccm_4['shrcd']==10) | (ccm_4['shrcd']==11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Form Q Factors 2*3*3\n",
    "# function to calculate value weighted return\n",
    "def wavg(group, avg_name, weight_name):\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "    \n",
    "# value-weigthed return\n",
    "vwret=ccm_5.groupby(['jdate','szport','iaport','roeport']).apply(wavg, 'retadj','wt').to_frame().reset_index().rename(columns={0: 'vwret'})\n",
    "vwret['sbport']=vwret['szport']+vwret['iaport']+vwret['roeport']\n",
    "# tranpose\n",
    "Q_factors=vwret.pivot(index='jdate', columns='sbport', values='vwret').reset_index()\n",
    "\n",
    "###create factors\n",
    "Q_factors['WB']=(Q_factors['BHD']+Q_factors['BHZ']+Q_factors['BHX']+Q_factors['BMD']+Q_factors['BMZ']+Q_factors['BMX']+Q_factors['BLD']+Q_factors['BLZ']+Q_factors['BLX'])/9\n",
    "Q_factors['WS']=(Q_factors['SHD']+Q_factors['SHZ']+Q_factors['SHX']+Q_factors['SMD']+Q_factors['SMZ']+Q_factors['SMX']+Q_factors['SLD']+Q_factors['SLZ']+Q_factors['SLX'])/9\n",
    "Q_factors['rME'] = Q_factors['WS']-Q_factors['WB']\n",
    "\n",
    "Q_factors['WH']=(Q_factors['BHD']+Q_factors['BHZ']+Q_factors['BHX']+Q_factors['SHD']+Q_factors['SHZ']+Q_factors['SHX'])/6\n",
    "Q_factors['WL']=(Q_factors['BLD']+Q_factors['BLZ']+Q_factors['BLX']+Q_factors['SLD']+Q_factors['SLZ']+Q_factors['SLX'])/6\n",
    "Q_factors['rINN'] = Q_factors['WH']-Q_factors['WL']\n",
    "\n",
    "Q_factors['WD']=(Q_factors['BHD']+Q_factors['BMD']+Q_factors['BLD']+Q_factors['SHD']+Q_factors['SMD']+Q_factors['SLD'])/6\n",
    "Q_factors['WX']=(Q_factors['BHX']+Q_factors['BMX']+Q_factors['BLX']+Q_factors['SHX']+Q_factors['SMX']+Q_factors['SLX'])/6\n",
    "Q_factors['rROE'] = Q_factors['WD']-Q_factors['WX']\n",
    "\n",
    "Q_factors=Q_factors.rename(columns={'jdate':'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
